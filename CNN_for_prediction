'''
简单CNN网络用于预测
模型参数以及数据集需要重新调整
created by chains
'''

import torch
import torch.nn as nn
import torch.utils.data as Data
import torchvision
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.metrics import mean_squared_error  #均方误差
from sklearn.metrics import r2_score            #R square
import random

#数据集的导入
df = pd.read_table("D:\\科研相关\\debutanizer_data.txt", sep='\s+', header=None)     #读取txt文件的数字部分，无表头[2394,8]
data = df.values
data = data.astype(np.float32)                                                      #size[2394,8]
#print(data.shape)
# index = [i for i in range(len(data))]
# random.shuffle(index)
# data = data[index]     #打乱数据集

#划分训练集测试集
train_data = data[:2000, ]
#print("original data:", train_data[1, :])
test_data = data[2000:2300, ]

#数据预处理
# std = StandardScaler()##
# train_data = std.fit_transform(train_data)           #size[2000,8]
# test_data = std.transform(test_data)                #size[2000,8]
#print("transformed data:", train_data[1, :])

#超参数的定义
EPOCH = 500          #training times
Batch_size = 25     #number of samples
LR = 0.001          #learning rate

#网络结构参数定义

Param = {
    'in_channels_conv1': 1,
    'out_channels_conv1': 4,
    'kernel_size_conv1': 3,
    'stride_conv1': 1,
    'padding_conv1': 1,
    'pool_conv1': 2,
    'out_channels_conv2': 8,
    'kernel_size_conv2': 3,
    'stride_conv2': 1,
    'padding_conv2': 1,
    'pool_conv2': 2,
    'output_size': 8*6*1
}

#CNN模型定义

class CNN(nn.Module):
    def __init__(self, **param):
        super(CNN, self).__init__()
        self.conv1 = nn.Sequential(
            nn.Conv2d(
                in_channels=param['in_channels_conv1'],                 #input height
                out_channels=param['out_channels_conv1'],               #layer 1 n_filters
                kernel_size=param['kernel_size_conv1'],                 #layer 1 filter size
                stride=param['stride_conv1'],                           #filter step
                padding=param['padding_conv1'],                         #padding size
            ),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=param['pool_conv1']),       #choose max value in 2x2 area
        )
        self.conv2 = nn.Sequential(
            nn.Conv2d(in_channels=param['out_channels_conv1'],
                      out_channels=param['out_channels_conv2'],
                      kernel_size=param['kernel_size_conv2'],
                      stride=param['stride_conv2'],
                      padding=param['padding_conv2']),
            nn.ReLU(),
            nn.MaxPool2d(param['pool_conv2'])
        )
        self.out = nn.Linear(param['output_size'], 25)
        self.dropout = nn.Dropout(p=0.3)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = x.view(x.size(0), -1)
        x = self.dropout(x)
        output = self.out(x)
        return output

#模型实例化
cnn = CNN(**Param)
print(cnn)
optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)
loss_func = nn.MSELoss()

#将数据集装入loader
train_x = train_data[:, :7]                                #[2000,7]
train_y = train_data[:, 7].reshape([2000, 1])              #[2000,1]
train_x = torch.from_numpy(train_x)
train_y = torch.from_numpy(train_y)

test_x = test_data[:, :7]                                  #[300,7]
test_y = test_data[:, 7].reshape([300, 1])                 #[300,1]
test_x = torch.from_numpy(test_x)
test_y = torch.from_numpy(test_y)

torch_train_dataset = Data.TensorDataset(train_x, train_y)                 #先将数据整理成一个DataSet类
torch_test_dataset = Data.TensorDataset(test_x, test_y)

loader_train = Data.DataLoader(
    dataset=torch_train_dataset,
    batch_size=Batch_size,
    shuffle=False,
    #num_workers=2
)

loader_test = Data.DataLoader(
    dataset=torch_test_dataset,
    batch_size=Batch_size,
    shuffle=False,
    #num_workers=2
)


#training
if __name__ == '__main__':
    Los = []
    for epoch in range(EPOCH):
        loss_sum = 0
        for i, data_set in enumerate(loader_train):
            inputs, labels = data_set
            inputs = inputs.view(1, 1, Batch_size, 7)
            outs = cnn(inputs)
            outs = outs.view(Batch_size, 1)
            loss = loss_func(outs, labels)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            loss_sum += loss.item()
            print("epoch:", epoch, "|batch:", i, "|loss:", loss.data.numpy())

        Los.append(loss_sum)
    plt.figure()
    plt.plot(range(len(Los)), Los, color='b')
    plt.show()

    #训练集测试
    output_train = []
    for i, Dataset in enumerate(loader_train):
        inputs, labels = Dataset
        inputs = inputs.view(1, 1, Batch_size, 7)
        outs = cnn(inputs)
        outs = outs.view(Batch_size, 1)
        outs = outs.data.numpy()
        output_train.append(outs)
    output_train = np.array(output_train)
    output_train = output_train.reshape([2000, 1])
    plt.figure()
    plt.plot(range(len(output_train)), output_train, color='b', label='y_trainpre')
    plt.plot(range(len(output_train)), train_y.data.numpy(), color='r', label='y_true')
    plt.legend()
    plt.show()
    train_rmse = np.sqrt(mean_squared_error(output_train, train_y.data.numpy()))
    train_r2 = r2_score(output_train, train_y.data.numpy())
    print('train_rmse = ' + str(round(train_rmse, 5)))
    print('train_r2 = ', str(train_r2))

    output_test = []
    for i, Dataset_test in enumerate(loader_test):
        inputs_test, labels_test = Dataset_test
        inputs_test = inputs_test.view(1, 1, Batch_size, 7)
        outs_test = cnn(inputs_test)
        outs_test = outs_test.view(Batch_size, 1)
        outs_test = outs_test.data.numpy()
        output_test.append(outs_test)
    output_test = np.array(output_test)
    output_test = output_test.reshape([300, 1])
    plt.figure()
    plt.plot(range(len(output_test)), output_test, color='b', label='y_trainpre')
    plt.plot(range(len(output_test)), test_y.data.numpy(), color='r', label='y_true')
    plt.legend()
    plt.show()
    test_rmse = np.sqrt(mean_squared_error(output_test, test_y.data.numpy()))
    test_r2 = r2_score(output_test, test_y.data.numpy())
    print('test_rmse = ' + str(round(test_rmse, 5)))
    print('r2 = ', str(test_r2))




